{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKF0YEl3ZAUN"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "x8FHageA5Xrx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6126a22f-7455-46e4-c7f0-6dbd6e46716f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dl4zNAFe_ydY"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import LSTM, Dense"
      ],
      "metadata": {
        "id": "O0kDrZmCRDQl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "9FpWm1np5mU_"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = 'TMP_DIR/lstm'\n",
        "LSTM_DATA_DIR = os.path.join('/content/drive/MyDrive', DATA_DIR)\n",
        "OUTPUT_DIR = os.path.join(LSTM_DATA_DIR, 'output')\n",
        "\n",
        "NUM_READ = 150\n",
        "NUM_SPLIT = 5\n",
        "NUM_SEED = 8\n",
        "STANDARD_DEVIATION = 1.0\n",
        "\n",
        "STATE = {\n",
        "    \"healthy\": 0, \n",
        "    \"sick group A\": 1,\n",
        "    \"sick group B\": 2\n",
        "}\n",
        "\n",
        "FEATURES = [\"movement_distance_head\", \"movement_distance_tail\", \"movement_distance_center\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "I0ca3-_ZbTuV"
      },
      "outputs": [],
      "source": [
        "def set_seeds(seed=8):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    session_conf = tf.compat.v1.ConfigProto(\n",
        "        intra_op_parallelism_threads=1,\n",
        "        inter_op_parallelism_threads=1\n",
        "    )\n",
        "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "    tf.compat.v1.keras.backend.set_session(sess)\n",
        "\n",
        "set_seeds(NUM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "fNcziOelXa2s"
      },
      "outputs": [],
      "source": [
        "def has_null(df):\n",
        "    if not df.notnull().all().all():\n",
        "        raise ValueError(\"Your data has null field.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "1HJjAcdwivoH"
      },
      "outputs": [],
      "source": [
        "def get_current_datetime_str() -> str:\n",
        "    now = str(datetime.now())\n",
        "    return f'{now[0:4]}{now[5:7]}{now[8:10]}{now[11:13]}{now[14:16]}{now[17:19]}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "cPEuG43NpkM9"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "Y = []\n",
        "y = []\n",
        "\n",
        "for state_dir in Path(LSTM_DATA_DIR).glob(\"*\"):\n",
        "    csv_paths = state_dir.glob(\"*.csv\")\n",
        "    for csv_path in csv_paths:\n",
        "        y.append(STATE[state_dir.name])\n",
        "        Y.append([STATE[state_dir.name], csv_path.name])\n",
        "        df = pd.read_csv(str(csv_path)).iloc[:NUM_READ]\n",
        "        df = df.loc[:, FEATURES]\n",
        "        has_null(df)\n",
        "        frames = []\n",
        "        X.append(frames)\n",
        "        for row in df.itertuples(name=None):\n",
        "            frames.append(row[1:])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "9JVCzyoKCMPx"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "xDJ-ZI7GCOoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLcexKKMZI-X"
      },
      "source": [
        "# Training using k-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = StratifiedKFold(n_splits=NUM_SPLIT, shuffle=True, random_state=NUM_SEED)"
      ],
      "metadata": {
        "id": "-IdrZFxoqz0R"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, (idx_train, idx_test) in enumerate(kfold.split(X, y)):\n",
        "    X_train = X[idx_train]\n",
        "    X_test = X[idx_test]\n",
        "    Y_train = Y[idx_train]\n",
        "    Y_test = Y[idx_test]\n",
        "\n",
        "    y_train, csvfilename_train = np.hsplit(Y_train, 2)\n",
        "    y_test, csvfilename_test = np.hsplit(Y_test, 2) \n",
        "    y_train = np.array(y_train.flatten(), dtype='uint8')\n",
        "    csvfilename_train = csvfilename_train.flatten()\n",
        "    y_test = np.array(y_test.flatten(), dtype='uint8')\n",
        "    csvfilename_test = csvfilename_test.flatten()\n",
        "    \n",
        "    model = keras.Sequential()\n",
        "    model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    print(model.summary())\n",
        "\n",
        "    idx_dir = \"cv\" + str(idx+1)\n",
        "\n",
        "    model_dir = os.path.join(OUTPUT_DIR, f'models/{idx_dir}')\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "    log_dir = os.path.join(OUTPUT_DIR, f'tensorlog/{idx_dir}')\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "    model_path = os.path.join(model_dir, f'{get_current_datetime_str()}.hdf5')\n",
        "    cp_cb = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "    tb_cb = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "    model.compile(\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "        optimizer=\"adam\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train,\n",
        "        y_train, \n",
        "        validation_data=(X_test, y_test), \n",
        "        batch_size=2, \n",
        "        epochs=30,     \n",
        "        callbacks=[\n",
        "            cp_cb,\n",
        "            tb_cb\n",
        "      ]\n",
        "    )\n",
        "\n",
        "    y_pred = tf.argmax(model.predict(X_test), axis=-1).numpy()\n",
        "    Y_analysis = np.array([y_test, y_pred, csvfilename_test])\n",
        "    Y_analysis = Y_analysis.transpose()\n",
        "\n",
        "    df_result = pd.DataFrame(data=Y_analysis, columns=['actual', 'pred', 'filename'])\n",
        "    result_dir = os.path.join(OUTPUT_DIR, f'result/{idx_dir}')\n",
        "    os.makedirs(result_dir, exist_ok=True)\n",
        "    df_result.to_csv(os.path.join(result_dir, 'result.csv'), index=False)"
      ],
      "metadata": {
        "id": "qLtH1ZHZq47W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(NUM_SPLIT):\n",
        "    preds = []\n",
        "    acts = []\n",
        "    idx_dir = \"cv\" + str(idx+1)\n",
        "    result_path = os.path.join(OUTPUT_DIR, f'result/{idx_dir}/result.csv')\n",
        "    df = pd.read_csv(result_path)\n",
        "\n",
        "    actual = df['actual']\n",
        "    acts.extend(actual.values)\n",
        "    pred = df['pred']\n",
        "    preds.extend(pred.values)\n",
        "    \n",
        "    acts = pd.Series(acts)\n",
        "    preds = pd.Series(preds)\n",
        "    cm = pd.DataFrame(\n",
        "        data=confusion_matrix(acts, preds),\n",
        "        index=[\"Healthy\", \"Sick group A\", \"Sick group B\"], \n",
        "        columns=[\"Healthy\", \"Sick group A\", \"Sick group B\"]\n",
        "    )\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(10,6))\n",
        "\n",
        "    sns.heatmap(cm, square=True, cbar=True, annot=True, cmap='Blues', fmt='d', ax=ax[0])\n",
        "    ax[0].set_title(\"About Count\")\n",
        "    ax[0].set_xlabel(\"Prediction\", fontsize=11, rotation=0)\n",
        "    ax[0].set_ylabel(\"Ground truth\", fontsize=11)\n",
        "\n",
        "    if idx == 0: \n",
        "        cv = str(idx+1) + \"st CV\"\n",
        "    elif idx == 1:\n",
        "        cv = str(idx+1) + \"nd CV\"\n",
        "    elif idx == 2:\n",
        "        cv = str(idx+1) + \"rd CV\"\n",
        "    else:\n",
        "        cv = str(idx+1) + \"th CV\"\n",
        "\n",
        "    fig.suptitle(f'Confusion matrix ({cv})', fontsize=16)\n",
        "    cm = cm.astype('float64')\n",
        "    num_data = len(acts)\n",
        "    for index, row in cm.iterrows():\n",
        "        row['Healthy'] = (row['Healthy'] / num_data)\n",
        "        row['Sick group A'] = (row['Sick group A'] / num_data)\n",
        "        row['Sick group B'] = (row['Sick group B'] / num_data)\n",
        "\n",
        "    sns.heatmap(cm, square=True, cbar=True, annot=True, cmap='Blues', fmt=\".3f\", ax=ax[1])\n",
        "    ax[1].set_title(\"About Ratio\")\n",
        "    ax[1].set_xlabel(\"Prediction\", fontsize=11, rotation=0)\n",
        "    ax[1].set_ylabel(\"Ground truth\", fontsize=11)\n",
        "\n",
        "    print(f\"--------------------Cross Validation Round {idx+1}--------------------\")\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Evaluation Index: [Healthy, Sick Group A, Sick Group B]\")\n",
        "    print(f'Racall: {recall_score(actual, pred, average=None)}')\n",
        "    print(f'Presision{precision_score(actual, pred, average=None)}')\n",
        "    print(f'F1 Score: {f1_score(actual, pred, average=None)}')\n",
        "    print(f'Accuracy: {accuracy_score(actual, pred)}')\n",
        "    print()"
      ],
      "metadata": {
        "id": "uR2TsjLtprRh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}